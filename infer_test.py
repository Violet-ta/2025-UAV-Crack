import os
import zipfile
import torch
import cv2
import numpy as np
from PIL import Image
from mmseg.apis import init_model, inference_model
from mmseg.utils import register_all_modules

register_all_modules()


def load_models(config_path, checkpoint_paths, device):
    models = []
    for ckpt in checkpoint_paths:
        model = init_model(config_path, ckpt, device=device)
        model.to(device)
        models.append(model)
    return models


def ensemble_predict(models, img_resized, device):
    """ä¼˜åŒ–ï¼šæ¦‚ç‡é”åŒ–+é€šé“åŠ æƒ"""
    all_preds = []
    with torch.no_grad():
        for model in models:
            result = inference_model(model, img_resized)
            pred = result.pred_sem_seg.data.squeeze().cpu().numpy()
            # 1. æ¦‚ç‡é”åŒ–ï¼ˆå¼ºåŒ–é«˜/ä½æ¦‚ç‡åŒºåˆ†åº¦ï¼‰
            pred = np.clip(pred, 0.05, 0.95)  # ç¼©å°æ¨¡ç³ŠåŒºé—´
            pred = (pred - 0.5) * 1.5 + 0.5  # æ‹‰ä¼¸æ¦‚ç‡åˆ†å¸ƒ
            pred = np.clip(pred, 0, 1)
            all_preds.append(pred)
    # 2. æ›´æç«¯çš„åŠ æƒï¼ˆbestæ¨¡å‹æƒé‡å 60%ï¼‰
    weights = [0.6, 0.15, 0.15, 0.1]
    avg_pred = np.average(all_preds, axis=0, weights=weights)
    return avg_pred


def dynamic_postprocess(mask, img_shape):
    h, w = img_shape
    # ä¼˜åŒ–ï¼šåˆ†åœºæ™¯è°ƒæ•´å½¢æ€å­¦æ ¸
    if h < 400 or w < 700:
        min_area = 12
        denoise_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        connect_kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (9, 9))  # åå­—æ ¸æ›´é€‚åˆå¯†é›†è£‚ç¼
    else:
        min_area = 8
        denoise_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
        connect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))

    # 1. å¼€è¿ç®—å»å™ª
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, denoise_kernel, iterations=1)
    # 2. é—­è¿ç®—è¿æ¥+è¾¹ç¼˜å¢å¼º
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, connect_kernel, iterations=2)
    # 3. è¾¹ç¼˜è†¨èƒ€ï¼ˆå¡«è¡¥ç»†è£‚ç¼ï¼‰
    kernel_edge = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
    mask = cv2.dilate(mask, kernel_edge, iterations=1)
    # 4. é¢ç§¯è¿‡æ»¤
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)
    for i in range(1, num_labels):
        if stats[i, cv2.CC_STAT_AREA] < min_area:
            mask[labels == i] = 0
    return mask


def main():
    config_path = 'outputs/uav_crack_unet_optimized/uav_crack_fcn_min.py'
    checkpoint_paths = [
        'outputs/uav_crack_unet_optimized/best_mIoU_iter_2250.pth',
        'outputs/uav_crack_unet_optimized/iter_2175.pth',
        'outputs/uav_crack_unet_optimized/iter_2200.pth',
        'outputs/uav_crack_unet_optimized/iter_2300.pth'
    ]
    img_dir = r'/tools/data\uav_crack\img_dir\val'
    output_dir = 'result'
    target_h, target_w = 378, 672

    # ä¼˜åŒ–ï¼šåŠ¨æ€é˜ˆå€¼+è£‚ç¼åŒºåŸŸä¼˜å…ˆ
    def get_dynamic_thres(img):
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        brightness = np.mean(gray)
        # æ–°å¢ï¼šæ£€æµ‹å›¾åƒä¸­æ˜¯å¦æœ‰ç–‘ä¼¼è£‚ç¼ï¼ˆé«˜å¯¹æ¯”åº¦åŒºåŸŸï¼‰
        edge = cv2.Canny(gray, 50, 150)
        has_crack = np.sum(edge) > 1000
        if has_crack:
            # æœ‰è£‚ç¼æ—¶é™ä½é˜ˆå€¼ï¼Œé¿å…æ¼æ£€
            return 0.28 if brightness < 80 else 0.33
        else:
            # æ— è£‚ç¼æ—¶æé«˜é˜ˆå€¼ï¼Œå‡å°‘å‡é˜³æ€§
            return 0.35 if brightness < 80 else 0.40

    os.makedirs(output_dir, exist_ok=True)
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    models = load_models(config_path, checkpoint_paths, device)
    print(f"ğŸš€ åŠ è½½ {len(models)} ä¸ªæ¨¡å‹å®Œæˆï¼ä½¿ç”¨è®¾å¤‡ï¼š{device}")

    img_files = [f for f in os.listdir(img_dir) if f.lower().endswith('.jpg')]
    print(f"ğŸ“ å¼€å§‹æ¨ç†ï¼ˆå…±{len(img_files)}å¼ å›¾åƒï¼‰...")

    for idx, img_name in enumerate(sorted(img_files)):
        img_path = os.path.join(img_dir, img_name)
        image_id = os.path.splitext(img_name)[0]
        output_mask_path = os.path.join(output_dir, f"{image_id}.png")

        img = cv2.imread(img_path)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img_resized = cv2.resize(img_rgb, (672, 384), interpolation=cv2.INTER_LINEAR)

        avg_pred = ensemble_predict(models, img_resized, device)

        # åŠ¨æ€é˜ˆå€¼ï¼ˆæ–°å¢è£‚ç¼æ£€æµ‹é€»è¾‘ï¼‰
        dynamic_thres = get_dynamic_thres(img_rgb)
        combined_mask = (avg_pred > dynamic_thres).astype(np.uint8)

        # åŠ¨æ€åå¤„ç†ï¼ˆæ–°å¢è¾¹ç¼˜è†¨èƒ€ï¼‰
        if combined_mask.max() > 0:
            combined_mask = dynamic_postprocess(combined_mask, img_rgb.shape[:2])

        pred_final = cv2.resize(combined_mask, (target_w, target_h), interpolation=cv2.INTER_NEAREST)
        mask_img = Image.fromarray(pred_final, mode='L')
        mask_img.save(output_mask_path, 'PNG', compress_level=0)

        if idx % 50 == 0:
            print(f"[{idx + 1:3d}/{len(img_files)}] ç”Ÿæˆæ©ç ï¼š{image_id}.pngï¼ˆé˜ˆå€¼ï¼š{dynamic_thres:.2f}ï¼‰")

    # ç”Ÿæˆæäº¤åŒ…
    zip_output_path = 'result.zip'
    with zipfile.ZipFile(zip_output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for root, _, files in os.walk(output_dir):
            for file in files:
                zipf.write(os.path.join(root, file), os.path.basename(file))
    print(f"âœ… æœ€ç»ˆä¼˜åŒ–æäº¤åŒ…ç”Ÿæˆå®Œæˆï¼š{os.path.abspath(zip_output_path)}")


if __name__ == '__main__':
    main()

